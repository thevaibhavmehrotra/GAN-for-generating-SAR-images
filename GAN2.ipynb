{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import matplotlib.pylab as plt\n",
    "#%matplotlib inline\n",
    "import os,random\n",
    "import cv2\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"theano\"\n",
    "#from keras.utils import np_utils\n",
    "import keras.models as models\n",
    "from keras.layers import Input,merge\n",
    "from keras.layers.core import Reshape,Dense,Dropout,Activation,Flatten#,MaxoutDense\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.activations import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, UpSampling2D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.regularizers import *\n",
    "from keras.layers.normalization import *\n",
    "from keras.optimizers import *\n",
    "from keras.datasets import mnist\n",
    "import _pickle as cPickle, random, sys, keras\n",
    "from keras.models import Model\n",
    "from IPython import display\n",
    "from keras.utils import np_utils\n",
    "from tqdm import tqdm\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 2000\n",
    "np.random.seed(seed)\n",
    "\n",
    "experiment='rv32by32_bs8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val\n",
    "        \n",
    "def get_stats(X):\n",
    "    print ('array shape:', X.shape)\n",
    "    print ('min: %s  max: %s  mean: %s  std: %s' %(np.min(X),np.max(X),np.mean(X),np.std(X)))\n",
    "    print ('-'*50)\n",
    "    \n",
    "def preprocess(X,Y,params):\n",
    "    \n",
    "    h=params['h']\n",
    "    w=params['w']\n",
    "    norm_type=params['norm_type']\n",
    "    \n",
    "    if Y is None:\n",
    "        Y=np.zero_like(X)\n",
    "        \n",
    "    # downsample    \n",
    "    X = cv2.resize(X, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "    Y = cv2.resize(Y, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # reshape        \n",
    "    X = np.transpose(X,(2,0,1))\n",
    "    X=np.expand_dims(X,axis=1)\n",
    "    Y = np.transpose(Y,(2,0,1))\n",
    "    Y=np.expand_dims(Y,axis=1)\n",
    "    \n",
    "\n",
    "    X = X.astype('float32')\n",
    "    if norm_type is 'minusplusone':\n",
    "        # normalized to [-1,1]\n",
    "        xmaxd2=np.max(X)/2\n",
    "        X-=xmaxd2\n",
    "        X/=xmaxd2## load data\n",
    "    elif norm_type is 'zeromeanunitvar':\n",
    "        X-=np.mean(X)\n",
    "        X/=np.std(X)\n",
    "    else:\n",
    "        X/=np.max(X)\n",
    "    return X,Y\n",
    "\n",
    "def plot_loss(losses):\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        plt.figure(figsize=(10,8))\n",
    "        plt.plot(losses[\"d\"], label='discriminitive loss')\n",
    "        plt.plot(losses[\"g\"], label='generative loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "def plot_gen(n_ex=8,dim=(4,4), figsize=(10,10) ):\n",
    "    noise = np.random.uniform(0,1,size=[n_ex,100])\n",
    "    generated_images = generator.predict(noise)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0],dim[1],2*i+1)\n",
    "        img = generated_images[i,0,:,:]\n",
    "        label = generated_images[i,1,:,:]>.5\n",
    "        plt.imshow(img,cmap='Greys_r')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(dim[0],dim[1],2*i+2)\n",
    "        plt.imshow(label,cmap='Greys_r')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def train_for_n(nb_epoch=5000, plt_frq=50,BATCH_SIZE=32):\n",
    "\n",
    "    for e in tqdm(range(nb_epoch)):  \n",
    "        \n",
    "        # Make generative images\n",
    "        image_batch = X_train[np.random.randint(0,X_train.shape[0],size=BATCH_SIZE),:,:,:]    \n",
    "        noise_gen = np.random.uniform(-1,1,size=[BATCH_SIZE,100])\n",
    "        generated_images = generator.predict(noise_gen)\n",
    "        \n",
    "        # Train discriminator on generated images\n",
    "        X = np.concatenate((image_batch, generated_images))\n",
    "        y = np.zeros([2*BATCH_SIZE,1])\n",
    "        y[0:BATCH_SIZE,0] = 1\n",
    "        #y[BATCH_SIZE:,0] = 1\n",
    "        \n",
    "        #make_trainable(discriminator,True)\n",
    "        d_loss  = discriminator.train_on_batch(X,y)\n",
    "        losses[\"d\"].append(d_loss)\n",
    "    \n",
    "        # train Generator-Discriminator stack on input noise to non-generated output class\n",
    "        noise_tr = np.random.uniform(-1,1,size=[BATCH_SIZE,100])\n",
    "        y2 = np.zeros([BATCH_SIZE,1])\n",
    "        y2[:,0] = 1\n",
    "        \n",
    "        #make_trainable(discriminator,False)\n",
    "        g_loss = GAN.train_on_batch(noise_tr, y2 )\n",
    "        losses[\"g\"].append(g_loss)\n",
    "        \n",
    "        # Updates plots\n",
    "        if e%plt_frq==plt_frq-1:\n",
    "            plot_loss(losses)\n",
    "            plot_gen()\n",
    "            \n",
    "def pick_large_contours(X,Y,threshold):\n",
    "    k1=0\n",
    "    for k in range(Y.shape[2]):\n",
    "        area=np.count_nonzero(Y[:,:,k])\n",
    "        if area>threshold:\n",
    "            if k1==0:\n",
    "                Xs=X[:,:,k]\n",
    "                Ys=Y[:,:,k]\n",
    "                Xs=np.expand_dims(Xs,axis=2)\n",
    "                Ys=np.expand_dims(Ys,axis=2)\n",
    "            else:\n",
    "                x1=X[:,:,k]\n",
    "                x1=np.expand_dims(x1,axis=2)                \n",
    "                Xs=np.append(Xs,x1,axis=2)\n",
    "                y1=Y[:,:,k]\n",
    "                y1=np.expand_dims(y1,axis=2)\n",
    "                Ys=np.append(Ys,y1,axis=2)\n",
    "            k1=k1+1\n",
    "    #print 'Xs:'  %Xs.shape      \n",
    "    #print 'Ys:'  %Ys.shape      \n",
    "    #print '-' *50\n",
    "    return Xs,Ys\n",
    "        \n",
    "def initNormal(shape, name=None):\n",
    "\treturn initializations.normal(shape, scale=0.02, name=name)    \n",
    "\n",
    "def grays_to_RGB(img):\n",
    "    # turn 2D grayscale image into grayscale RGB\n",
    "    return np.dstack((img, img, img))\n",
    "\n",
    "\n",
    "def image_with_mask(img, mask,color=(0,255,0)):\n",
    "    #img=np.asarray(img,dtype='uint8')\n",
    "    mask=np.asarray(mask,dtype='uint8') \n",
    "    if np.max(mask)==1:\n",
    "        mask=mask*255\n",
    "\n",
    "    # returns a copy of the image with edges of the mask added in red\n",
    "    if len(img.shape)==2:\t\n",
    "        img_color = grays_to_RGB(img)\n",
    "    else:\n",
    "        img_color =img\n",
    "\n",
    "    mask_edges = cv2.Canny(mask, 100, 200) > 0\n",
    "    img_color[mask_edges, 0] = color[0]  # set channel 0 to bright red, green & blue channels to 0\n",
    "    img_color[mask_edges, 1] = color[1]\n",
    "    img_color[mask_edges, 2] = color[2]\n",
    "    img_color=img_color#/float(np.max(img))\n",
    "    plt.axis('off')\n",
    "    return img_color\n",
    "\n",
    "\n",
    "def plot_real(n_ex=8,dim=(4,4), figsize=(10,10) ):\n",
    "    \n",
    "    idx = np.random.randint(0,X_train.shape[0],n_ex)\n",
    "    generated_images = X_train[idx,:,:,:]\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0],dim[1],2*i+1)\n",
    "        img = generated_images[i,0,:,:]\n",
    "        plt.imshow(img,cmap='Greys_r')\n",
    "\n",
    "        plt.subplot(dim[0],dim[1],2*i+2)\n",
    "        label = generated_images[i,1,:,:]\n",
    "        plt.imshow(label,cmap='Greys_r')\n",
    "        \n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\data\\test1\\train_HR\\\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 3)\n",
      "(512, 3)\n",
      "(512, 3)\n",
      "(512, 3)\n",
      "(512, 3)\n",
      "(512, 3)\n",
      "(512, 3)\n",
      "(512, 3)\n",
      "(512, 3)\n",
      "(512, 3)\n",
      "(512, 3)\n",
      "(512, 3)\n",
      "(512, 3)\n",
      "(512, 3)\n",
      "(512, 3)\n",
      "(512, 3)\n",
      "(512, 3)\n",
      "(512, 3)\n",
      "(512, 3)\n",
      "(512, 3)\n",
      "(512, 3)\n",
      "(512, 3)\n",
      "(512, 3)\n",
      "(512, 3)\n",
      "(512, 3)\n",
      "(25, 3, 512, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\npath2data='.\\\\data\\\\test1\\\\train_label\\\\'\\n\\nimage_list = []\\nprint(path2data)\\nfor file in os.listdir(path2data):\\n    img_test = cv2.imread(path2data+file)\\n    image_list.append(img_test)\\n\\nY_train = image_list\\n\\n\\n\\npath2data='.\\\\data\\\\test1\\\\test_HR\\\\'\\nimage_list = []\\nprint(path2data)\\nfor file in os.listdir(path2data):\\n    img_test = cv2.imread(path2data+file)\\n    image_list.append(img_test)\\n\\nprint(len(image_list))\\n#X_train = np.append(X_train,image_list)#,axis=1)\\nX_train.append(image_list)\\n\\npath2data='.\\\\data\\\\test1\\\\test_label\\\\'\\nimage_list = []\\nprint(path2data)\\nfor file in os.listdir(path2data):\\n    img_test = cv2.imread(path2data+file)\\n    image_list.append(img_test)\\n\\nY_train = np.append(Y_train,image_list)#,axis=2)\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##LOAD DATA\n",
    "\n",
    "path2data='.\\\\data\\\\test1\\\\train_HR\\\\'\n",
    "h, w = 512, 512\n",
    "\n",
    "train_list = []\n",
    "print(path2data)\n",
    "for file in os.listdir(path2data):\n",
    "    img_test = cv2.imread(path2data+file)\n",
    "    print(img_test.shape)\n",
    "    train_list.append(img_test)\n",
    "\n",
    "\n",
    "print(train_list[0].shape)\n",
    "#X_train = train_list\n",
    "\n",
    "X_train = []\n",
    "for item in train_list:\n",
    "    print(item[0].shape)\n",
    "    X_train.append((item[0],item[1],item[2]))\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "print(X_train.shape)\n",
    "\"\"\"\n",
    "path2data='.\\\\data\\\\test1\\\\train_label\\\\'\n",
    "\n",
    "image_list = []\n",
    "print(path2data)\n",
    "for file in os.listdir(path2data):\n",
    "    img_test = cv2.imread(path2data+file)\n",
    "    image_list.append(img_test)\n",
    "\n",
    "Y_train = image_list\n",
    "\n",
    "\n",
    "\n",
    "path2data='.\\\\data\\\\test1\\\\test_HR\\\\'\n",
    "image_list = []\n",
    "print(path2data)\n",
    "for file in os.listdir(path2data):\n",
    "    img_test = cv2.imread(path2data+file)\n",
    "    image_list.append(img_test)\n",
    "\n",
    "print(len(image_list))\n",
    "#X_train = np.append(X_train,image_list)#,axis=1)\n",
    "X_train.append(image_list)\n",
    "\n",
    "path2data='.\\\\data\\\\test1\\\\test_label\\\\'\n",
    "image_list = []\n",
    "print(path2data)\n",
    "for file in os.listdir(path2data):\n",
    "    img_test = cv2.imread(path2data+file)\n",
    "    image_list.append(img_test)\n",
    "\n",
    "Y_train = np.append(Y_train,image_list)#,axis=2)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23592960\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
